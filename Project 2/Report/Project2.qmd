---
title: "Evaluating the Impact of Behavioral Activation on Smoking Cessation in Major Depressive Disorder"
author: "Zhaoxiang Ding"
format: pdf
date: last-modified
date-format: "long"
bibliography: references.bib
execute:
  echo: false
  warning: false
  message: false
---

## Abstract

Behavioral Activation (BA) has been proposed as a treatment to support smoking cessation in individuals with Major Depressive Disorder (MDD), though evidence regarding its effectiveness remains limited. This study re-evaluates the impact of BA on smoking cessation, utilizing data from a prior 2x2 factorial randomized controlled trial. Our primary objectives are to investigate potential moderators of BA's effect on end-of-treatment (EOT) smoking abstinence and to identify baseline predictors of abstinence while accounting for pharmacotherapy. We adopt a logistic regression framework to estimate the causal effect, examining odds of abstinence rather than abstinence rates, and incorporate interaction terms to capture nuanced treatment effects. Findings confirm that BA does not significantly influence smoking cessation, aligning with prior results. However, several baseline predictors, including ftcd_score, NHW, and NMR, demonstrate strong associations with abstinence, and Age moderates the effect of pharmacotherapy on cessation. While this model offers valuable insights, limitations such as sample size constraints and potential model dependency suggest a need for further research.

## Introduction

Behavioral Activation (BA) is regarded as a promising intervention for aiding smoking cessation in individuals diagnosed with Major Depressive Disorder (MDD), who are known to be more likely to smoke heavily, exhibit greater nicotine dependence, and experience more severe withdrawal symptoms than those without MDD[@Hitsman_2023]. However, there has been limited research examining the specific impact of BA on smoking cessation outcomes. In one study, @Hitsman_2023 employed a 2x2 randomized factorial design (BA versus standard behavioral treatment (ST) and varenicline versus placebo, which is effect drug to help smoking cessation) to investigate this effect, concluding that BA did not significantly improve smoking cessation outcomes. This project aims to revisit the influence of BA on smoking cessation, using the same dataset from @Hitsman_2023 but with an alternative analytical approach.

Our objective is to explore potential moderators influencing the effectiveness of behavioral treatment on end-of-treatment (EOT) abstinence rates. Additionally, we seek to identify baseline characteristics that may predict abstinence, while accounting for the effects of behavioral treatment and pharmacotherapy(varenicline).

## Identifing the causal effect

In @Hitsman_2023's work, the causal effect was estimated by comparing the abstinence rates between the treatment and control groups, following an intent-to-treat (ITT) approach. Rather than solely examining abstinence rates, this project evaluates the odds of abstinence and estimates the causal effect using the odds ratio of abstinence between the treatment and control groups, while adhering to ITT principles. The causal effect, denoted as $\hat{\tau}$, can be formulated as follows:

$$
\hat{\tau} = \frac{E[odds(Y^1)]}{E[odds(Y^0)]}
$$

```{r}
library(gtsummary)
library(mice)
library(glmnet)
library(pROC)
library(kableExtra)
library(dplyr)
library(L0Learn)
```

```{r}
# Read data
data <- read.csv("../Data/project2.csv")
num_col <- c(5,12,14:19,23,25)
ordinal_col <- c(10,11)
data[,num_col] <- lapply(data[,num_col], as.numeric)
data[,ordinal_col] <- lapply(data[,ordinal_col], factor, order = T)

data[,-c(num_col, ordinal_col)] <- lapply(data[,-c(num_col, ordinal_col)], factor)
```
```{r}
#| label: tbl-eda
#| tbl-cap: Summary of the data
# summary table
data_tbl <- data[, -1]
data_tbl$group <- paste(data_tbl$Var, data_tbl$BA, sep = "_")
data_tbl$group <- case_when(data_tbl$group == "0_0" ~ "Control",
                            data_tbl$group == "1_0" ~ "BA + Placebo",
                            data_tbl$group == "0_1" ~ "ST + Varenicline",
                            data_tbl$group == "1_1" ~ "BA + Varenicline")
data_tbl <- data_tbl[, -c(2,3)]
tbl_summary(data_tbl, by = group, type = list(readiness ~ 'continuous')) %>%
  as_kable_extra(booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = "scale_down")
```

The dataset originates from a 2x2 randomized factorial design, theoretically balancing all covariates across treatment and control groups. As examined in @tbl-eda, baseline covariate distributions confirm that randomization was successful, as covariates appear balanced between groups. The table also reveals some missing data. While the data may not be missing at random, the low proportion of missing records suggests a minimal impact on the results, allowing us to treat the missingness as random. Therefore, the assumptions for identifying causal effects are met, and we express the causal effect as:

$$
\begin{aligned}
\hat{\tau} &= \frac{E[odds(Y^1)]}{E[odds(Y^0)])} \\
&= \frac{E[odds(Y)|A = 1]}{E[odds(Y)|A = 0]}
\end{aligned}
$$

Where $A$ is the whether having behavioral treatment or not. A naive approach to estimate the causal effect is to fit a logistic regression model with the treatment group as the only covariate. The causal effect can be estimated by the coefficient of the treatment group. However, this approach does not consider the potential interaction between the treatment group and other covariates, nor the moderation of other variables. In this project, we fit a logistic regression model with the treatment group and the interaction terms between the treatment group and other covariates. The regression model can be written as:

$$
E[logit(Y_i)] = \beta_0  + \beta_1A_i + \beta_2Z_i + \beta_3X_i^T  + \beta_4X_i^TA_i + \beta_5X_i^TZ_i +\beta_6Z_iA_i + \sum_{k=1}^K\beta_7X_{ik}X_{-ik}^T
$$
Where $A$ is whether having behavior treatment and $Z$ is whether taking varenicline, $X^T$ is the patient's baseline covariates and $X_{ik}X_{-ik}^T$ is the interaction terms of baseline covariates with $K$ is the number of interaction terms. The causal effect then can be estimated by the coefficient of the treatment group:

$$
\hat{\tau_i} =  \beta_1 + \beta_4X_i^T + \beta_6Z_i
$$

Except for identifying the causal effect, this logistic regression model can also be used to examine the potential moderators of the effect of behavioral treatment on end-of-treatment (EOT) abstinence and evaluate baseline variables as predictors of abstinence, controlling for behavioral treatment and pharmacotherapy. 

In order to examine the whther linearity assumtpion of the logistic regression model is met, we first examine the distributions of  continuous variables. Most continuous variables are normally distributed except for variable `hedonsum_y_pq1` and `shaps_score_pq1`, as shown in @fig-continuous. We will conduct a log transformation on these two variables to meet the linearity assumption.

```{r}
#| label: fig-continuous
#| fig-cap: Relationship between continuous variables and the outcome variable

# continuous variables
par(mfrow=c(2,5))
data_con <- data[,num_col]
hist_list <- apply(data_con, 2, function(x) hist(x, breaks = 20, main = '', xlab = ""))
```

## Identifing the interactions

Given that many variables in the dataset are categorical, including all possible interaction terms would produce more terms than the sample size allows, leading to model overfitting. To avoid this, we manually select covariates for inclusion based on the significance of their marginal main effects.

```{r}
#| label: tbl-contigency
#| tbl-cap: Contigency table of the data
# Contigency table
tbl_summary(data_tbl[,-23], by = abst, type = list(readiness ~ 'continuous')) %>%
  add_p() 
```

The contingency table indicates that three variables exhibit significant marginal main effects: `NHW`, `ftcd_score` and `NMR`. `cpd_ps` has a p-value of 0.052, which, combined with established knowledge of the influence of psychological variables on smoking cessation, justifies its inclusion in the interaction terms.

Therefor, the model can be written as:

$$
E[logit(Y_i)] = \beta_0  + \beta_1A_i + \beta_2Z_i + \beta_3X_i^T  + \beta_4X_i^TA_i + \beta_5X_i^TZ_i +\beta_6Z_iA_i + \sum_{k=1}^K\beta_7L_kL_{-k}^T
$$
Where $L_k$ is the kth significant main effect, and $L_{-k}$ is the rest of the main effects. and $L = \{NHW, \ ftcd\_score,\  NMR,\ cpd\_ps\}$

## Model selection

The primary goal of this project is to identify potential moderators of behavioral treatment effects on EOT abstinence and assess baseline predictors of abstinence, while controlling for behavioral treatment and pharmacotherapy. We explored various variable selection techniques, including Lasso regression, subset selection with an L0 penalty, and ridge regression, all implemented with 10-fold cross-validation on 80% of the data, with testing on the remaining 20%. Multiple imputation addressed missing values in the dataset.

```{r}
#multiple imputation
data_imp <- mice(data[,-1], m = 5, seed = 2550, printFlag = F)
data_imp <- complete(data_imp)
train_index <- sample(1:nrow(data_imp), 0.8*nrow(data_imp))
train_data <- data_imp[train_index,]
test_data <- data_imp[-train_index,]
```

```{r}
#| label: fig-lasso
#| fig-cap: AUC of Lasso regression and Ridge regression
# Lasso and ridge regression
# X <- model.matrix(abst~ . + (NHW + edu + ftcd_score + NMR +
#                                bdi_score_w00 + mde_curr)^2 + Var*(.) + BA*(.), 
#                   data = train_data)
X <- model.matrix(abst ~ . + (NHW + ftcd_score + NMR + cpd_ps)^2 + Var*(.) + BA*(.), 
                   data = train_data)
X <- X[,-1]
Y <- factor(train_data$abst)
lasso_fit <- cv.glmnet(X, Y, family = "binomial", alpha = 1, type.measure = "auc", nfolds = 10)
ridge_fit <- cv.glmnet(X, Y, family = "binomial", alpha = 0, type.measure = "auc", nfolds = 10)
auc_train_l <- roc(train_data$abst, predict(lasso_fit, type = "response", newx = X))
auc_train_r <- roc(train_data$abst, predict(ridge_fit, type = "response", newx = X))
plot.roc(auc_train_l, print.auc=TRUE, col = 'black')
plot.roc(auc_train_r, print.auc=TRUE, col = 'blue', add = TRUE, print.auc.x = 0.5, print.auc.y = 0.4)
legend("bottomright", legend = c("Lasso", "Ridge"), col = c("black", "blue"), lty = 1)
```

The penalty parameters for both Lasso and Ridge regressions were selected by identifying the largest parameter value within one standard error of the minimum cross validation error. As shown in @fig-lasso, Ridge regression achieved a higher AUC than Lasso regression, suggesting stronger performance. However, as Ridge regression does not shrink coefficients to zero, it cannot facilitate variable selection.

```{r}
#| label: fig-elbow
#| fig-cap: Sequences of cross-validation errors of subset selection with L0 penalty and L0L1 penalty 
#subset selection
par(mfrow=c(2,2))
set.seed(2550)
subset_fit = L0Learn.cvfit(X, Y, nFolds=10, penalty="L0", loss = 'Logistic')
plot(subset_fit$cvMeans[[1]], ylab = "CV error", main = "L0 penalty", cex.main = 0.5)
subset_fit1 = L0Learn.cvfit(X, Y, nFolds=10, penalty="L0L1", loss = 'Logistic')
plot(sapply(subset_fit1$cvMeans, mean), ylab = "CV error", main = "L0L1 Penalty, Gamma", cex.main = 0.5) # choose gamma
plot(subset_fit1$cvMeans[[3]], ylab = "CV error", main = "L0L1 Penalty, Lambda", cex.main = 0.5) # choose lambda
#coef(subset_fit, subset_fit$fit$lambda[[1]][10], 0)
#coef(subset_fit1, subset_fit1$fit$lambda[[4]][10], subset_fit1$fit$gamma[4])
```

The penalty parameter of subset selection with L0 penalty and L0L1 penalty is selected by selecting the elbow point of the cross-validation errors. As shown in @fig-elbow, the parameter for L0 penalty is the 20th lambda value(0.356). The parameter for L1 penalty of L0L1 penalty is the 3rd gamma value(0.244) and the parameter for L0 penalty of L0L1 penalty is the 10th lambda value(1.140).

```{r}
#| label: fig-roc-01
#| fig-cap: AUC of subset selection with L0 penalty and L0L1 penalty
# subset regression auc
auc_train_sub0 <- roc(train_data$abst, as.numeric(predict(subset_fit, 
                                                          type = "response",
                                                          newx = X, 
                                                          subset_fit$fit$lambda[[1]][20], 
                                                          0)))
auc_train_sub1 <- roc(train_data$abst, as.numeric(predict(subset_fit1, 
                                                          type = "response",
                                                          newx = X, 
                                                          subset_fit1$fit$lambda[[3]][10], 
                                                          subset_fit1$fit$gamma[3])))
plot.roc(auc_train_sub0, print.auc=TRUE, col = 'red')
plot.roc(auc_train_sub1, print.auc=TRUE, col = 'green', add = TRUE, print.auc.x = 0.5, print.auc.y = 0.4)
legend("bottomright", legend = c("L0", "L0L1"), col = c("red", "green"), lty = 1)
```

@fig-roc-01 shows that subset selection with L0 penalty has a higher AUC than subset selection with L0L1 penalty, indicating that subset selection with L0 penalty has a better performance.

```{r}
#| label: fig-roc-test
#| fig-cap: AUC of four models in test data
# model performance in test data
test_X <- model.matrix(abst~ . + (NHW + ftcd_score + NMR + cpd_ps)^2 + Var*(.) + BA*(.), 
                   data = test_data)
test_X <- test_X[,-1]
test_Y <- factor(test_data$abst)

auc_test_l <- roc(test_Y, predict(lasso_fit, type = "response", newx = test_X))
auc_test_r <- roc(test_Y, predict(ridge_fit, type = "response", newx = test_X))
auc_test_sub0 <- roc(test_Y, as.numeric(predict(subset_fit, 
                                                          type = "response",
                                                          newx = test_X, 
                                                          subset_fit$fit$lambda[[1]][20], 
                                                          0)))
auc_test_sub1 <- roc(test_Y, as.numeric(predict(subset_fit1, 
                                                          type = "response",
                                                          newx = test_X, 
                                                          subset_fit1$fit$lambda[[3]][10], 
                                                          subset_fit1$fit$gamma[3])))
plot.roc(auc_test_l, print.auc=TRUE, col = 'black')
plot.roc(auc_test_r, print.auc=TRUE, col = 'blue', add = TRUE, print.auc.x = 0.5, print.auc.y = 0.4)
plot.roc(auc_test_sub0, print.auc=TRUE, col = 'red', add = TRUE, print.auc.x = 0.5, print.auc.y = 0.3)
plot.roc(auc_test_sub1, print.auc=TRUE, col = 'green', add = TRUE, print.auc.x = 0.5, print.auc.y = 0.2)
legend("bottomright", legend = c("Lasso", "Ridge", "L0", "L0L1"), col = c("black", "blue","red", "green"), lty = 1)

```

@fig-roc-test shows the models' performance in test data. Subset selection model with L0 and L1 penalty have the highest AUC among all models, indicating the model is robust. It is worth to notice that lasso regression, eventhough have a lower AUC than subset selection with ridge regression, performs better for the purpose of hight sensitivity. Based on this result, we use the model with both L0 and L1 penalty to answer our research question. The result of the model is shown in @tbl-coef. The model exclude all but 3 terms, including all terms with behaviour treatment. Indicating that the behaviour treatment has no effect on addressing smoking cessation among MDD patients. 

Eventhough the model shows that behaviour treatment has no effect on smoking cessation, it can still help us to identify important predictors. `ftcd_score` can served as a good predictor for smoking cessation, with one unit increase will decrease the odds of quitting smoking by 20%. `NHW` and `NMR` are also valid predictor. With in non hispanic white population, one unite increase in NMR will increase the odds of quitting smoking by 300%. Age is only a significant predictor among people who take varenicline, with 1 year increase in age will increase the odds of quitting smoking by 2%.

```{r}
#| label: tbl-coef
#| fig-cap: Coefficients of best model
# model's result
coef_l0 <- coef(subset_fit1, subset_fit1$fit$lambda[[3]][10], subset_fit1$fit$gamma[3])
coef_l0_names <- row.names(coef(lasso_fit))
coef_l0_index <- which(coef_l0 != 0)
coef_l0 <- coef_l0[coef_l0_index]
coef_l0_names <- coef_l0_names[coef_l0_index]

coef_lasso <- coef(lasso_fit)
coef_lasso_names <- row.names(coef_lasso)
coef_lasso_index <- which(coef_lasso != 0)
coef_lasso <- coef_lasso[coef_lasso_index]
coef_lasso_names <- coef_lasso_names[coef_lasso_index]

coef_tbl <- data.frame(Variable = coef_l0_names, Coefficients = coef_l0)
coef_tbl %>%
  kable(format = "latex", booktabs = T) %>%
  kable_styling(latex_options = "scale_down")
```

## Discussion

The result of this project shows that behaviour treatment has no effect on smoking cessation among MDD patients. This finding corresponds with the result of @, which also found that BA does not have a significant effect on smoking cessation. Possible explanations for this result has already been discussed in @Hitsman_2023.

Several important predictors are identified in this project. `ftcd_score`, `NHW` and `NMR` are predicyors for smoking cessation. `Age` is identified as the moderator of the effect of `Var` on smoking cessation. 

This project has several limitations. First of all, the model selected to use will have a large impact on the result. The subset selection model with L0 and L1 penalty is selected as the best model in this project, but other models may have different results. For example, the lasso regression model(@tbl-coef-lasso) shows that behaviour treatment has effect on smoking cessation, and the effect is moderated by `inc` and `bdi score`, but considering the low effect size of the interaction terms, whether the effect is significant or not is still questionable. Second, the data set only contains limited sample size, making examining the effect of interaction terms difficult. As shown in the previous section, only limited interaction terms are included in the model while those interaction terms excluded from the model may also have significant effect.

```{r}
#| label: tbl-coef-lasso
#| fig-cap: Coefficients of lasso regression model
coef_lasso_tb <- data.frame(Variable = coef_lasso_names, Coefficients = coef_lasso)
coef_lasso_tb %>%
  kable(format = "latex", booktabs = T) %>%
  kable_styling(latex_options = "scale_down")
```

In conclusion, this project re-evaluates the impact of BA on smoking cessation in MDD patients. The results confirm that BA does not significantly influence smoking cessation, consistent with prior findings. Several baseline predictors, including `ftcd_score`, `NHW`, and `NMR`, demonstrate strong associations with abstinence, while `Age` moderates the effect of pharmacotherapy on cessation. Despite limitations, this model offers valuable insights into the predictors of smoking cessation in MDD patients, highlighting the need for further research to confirm these findings.

## References

::: {#refs}
:::

## Code Appendix

```{r ref.label = knitr::all_labels()}
#| echo: true
#| eval: false
```
